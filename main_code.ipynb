{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODIGO PRINCIPAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se incluyen las ejecuciones de los programas desarrollados en el proyecto de forma secuencial.\n",
    "\n",
    "En concreto este código está dedicado a los capítulos del trabajo indicados a continuación:\n",
    "\n",
    "    3. Sistema, diseño y desarrollo\n",
    "    4. Experimentos realizados y resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar funciones y módulos requeridos\n",
    "\n",
    "El módulo *nimgenetics.py* contiene las funciones necesarias para ejecutar este código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('./my_module/')\n",
    "import nimgenetics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SISTEMA, DISEÑO Y DESARROLLO\n",
    "\n",
    "     \n",
    "Directorios importantes:\n",
    "     \n",
    "- folder_path: carpeta donde se ubican los informes de NIMGenetics.\n",
    "- folder_result: carpeta donde se irán guardando los resultados de las ejecuciones de los programas.\n",
    "- pathI: path de la carpeta \"Identificados\" de los informes que cumplen el patrón de selección.\n",
    "- image_path: carpeta donde se almacenan las imágenes generadas a partir de los informes.\n",
    "- textos: carpeta donde se almacenan los textos generados a partir de las imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'path_to_folder_root'\n",
    "folder_result = 'path_to_folder_result'\n",
    "pathI = 'path_to_folder_identificados'\n",
    "image_path = 'path_to_images'\n",
    "textos = 'path_to_textos'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Obtención de informes clínicos de Gestlab\n",
    "Informes filtrados y renombrados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Mapeo de los informes localizados en folder_path\n",
    "La función load_files es utilizada para mapear los informes (PDF) dentro de folder_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_path contiene el path absoluto de todos los informes\n",
    "l_path = nimgenetics.load_files(root_dir=folder_path)[0]\n",
    "# l_pdf es el mapeo individual de cada informe\n",
    "l_pdf = nimgenetics.load_files(root_dir=folder_path)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Obtención de los identificadores reales de los informes\n",
    "La función getIDs realiza una consulta sql a Gestlab para obtener los identificadores reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id_peticion es una lista con los ID reales obtenidos tras la decodificación hexadecimal\n",
    "id_peticion = []\n",
    "for pdf in l_pdf:\n",
    "    # split por guion bajo\n",
    "    s_pdf = pdf.split('_')\n",
    "    # transformación del segundo componente en hexadecimal del identificador\n",
    "    hex_id = int(s_pdf[1],16)\n",
    "    id_peticion.append(hex_id)\n",
    "\n",
    "# ejecución de la función getIDs\n",
    "r_id = nimgenetics.getIDs(id_list=id_peticion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Almacenamiento de los informes con su ID correcto\n",
    "Selección de informes que cumplen un patrón específico: identifiedPDF.\n",
    "\n",
    "Informes cuyo identificador es desconocido: emptyPDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar una lista que almacene todos los identificadores provenientes de r_id\n",
    "# l_names a diferencia de la anterior no es una lista de listas\n",
    "l_names = []   \n",
    "for row in r_id:\n",
    "    try:\n",
    "        # Primer bloque: extraer identificadores que cumplan la siguiente estructura\n",
    "        l_names.append(row[0][0])\n",
    "    except:\n",
    "        # Segundo bloque: identificadores que devuelven elementos vacios\n",
    "        # Estos informes se almacenarán con su identificador hexadecimal original\n",
    "        s_row = str(row)\n",
    "        if s_row == '[]':\n",
    "            # Almacenamos en l_names los identificadores reemplazados con el literal 'sin_id'\n",
    "            sr_row = s_row.replace('[]', 'sin_id')\n",
    "            l_names.append(sr_row)\n",
    "\n",
    "\n",
    "# Función utilizada para almacenar los informes que cumplen un patrón de selección pre-establecido\n",
    "# También se almacenan los informes que están repetidos y los descartados que no cumplen el patrón\n",
    "# con la finalidad de no perder información\n",
    "nimgenetics.identifiedPDF(folder_path=folder_result, list_id=l_names, list_path=l_path)\n",
    "\n",
    "# Función para almacenar los informes cuyo identificador no ha sido recuperado de la base de datos\n",
    "# Estos informes son guardados con el identificador hexadecimal original\n",
    "nimgenetics.emptyPDF(folder_path=folder_result, list_id=l_names, list_path=l_path, list_pdf=l_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Conversión de los informes a texto plano para la extracción de terminología médica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdfPath contiene el path absoluto de todos los pdf \n",
    "# este paso es necesario para ejecutar el siguiente programa: pdfToImage\n",
    "pdfPath = nimgenetics.absolutePath(dpath=pathI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Generación de imágenes en formato PNG a partir de los informes escaneados\n",
    "Este procedimiento involucra la ejecución de la función pdfToImage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución de la función pdfToImage\n",
    "nimgenetics.pdfToImage(f_path=folder_result, pdf_list=pdfPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Generación de texto plano a partir de imágenes PNG\n",
    "Este procedimiento involucra la ejecución de dos funciones: makeCorpus y ocrToImage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecución de la función makeCorpus la cual integra en su código ocrToImage\n",
    "# Necesario image_path como parámetro para la correcta ejecución de la función\n",
    "# El resultado de este proceso guarda los resultados en la carpeta textos\n",
    "nimgenetics.makeCorpus(f_path=folder_result, image_path=image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. EXPERIMENTOS REALIZADOS Y RESULTADOS\n",
    "\n",
    "Directorios importantes:\n",
    "\n",
    "- cutext_results: carpeta que incluye los resultados de la ejecución de CUTEXT.\n",
    "- cutext_corpus: carpeta que alberga el corpus elaborado al procesar los resultados de CUTEXT.\n",
    "- megadict: path donde se localiza el megadiccionario.\n",
    "- lookup_corpus: path donde almacenar el corpus generado por la estrategia lookup.\n",
    "- corpus_global: path donde guardar el corpus global elaborado a partir de cutext y lookup.\n",
    "- lookup_corpus_uncleaned: path donde se almacena el corpus de lookup sin proceso de curación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutext_results = 'path_to_save_cutext_results'\n",
    "cutext_corpus = 'path_to_save_cutext_corpus'\n",
    "megadict = 'path_to_megadict'\n",
    "lookup_corpus = 'path_to_lookup_corpus'\n",
    "corpus_global = 'path_to_merge_corpus'\n",
    "lookup_corpus_uncleaned = 'path_to_lookup_corpusUncleaned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_textos contiene el path absoluto de los textos\n",
    "path_textos = nimgenetics.absolutePath(dpath=textos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Extracción de terminología mediante CUTEXT\n",
    "Ejecutar la función getCutextResults que integra la funcionalidad de CUTEXT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path a la carpeta in de cutext\n",
    "cutext_in = 'path_to_cutext_in_folder'\n",
    "# path del output generado por cutext\n",
    "out = 'path_to_cutext_output_folder'\n",
    "# El output de cutext se almacenará en cutext_results\n",
    "# ejecución de la función que integra la funcionalidad de cutext\n",
    "nimgenetics.getCutextResults(cutext_in=cutext_in, textos_ori=path_textos, old=out, new=cutext_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Elaboración de un corpus final a partir de los resultados CUTEXT\n",
    "La función cutextCorpus procesa los resultados generados en el apartado anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path absoluto de los resultados de cutext\n",
    "l_cutext = nimgenetics.absolutePath(dpath=cutext_results)\n",
    "\n",
    "# Ejecución del programa que genera el corpus de cutext\n",
    "# El resultado se almacena en cutext_corpus\n",
    "nimgenetics.cutextCorpus(lista_cutext=l_cutext, path_to_words=cutext_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Extracción de terminología mediante estrategia lookup\n",
    "\n",
    "La función lookup genera un corpus elaborado utilizando esta estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacenamos el corpus de lookup en lookup_corpus\n",
    "nimgenetics.lookup(textos_ori=path_textos, megadict=megadict, path_to_words=lookup_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 Elaboración de un corpus global a partir de cutext y lookup\n",
    "La función mergeCorpus implica la construcción de un corpus que alberga la terminología extraída mediante cutext y la estrategia lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este proceso genera el corpus global y se almacena en corpus_global\n",
    "nimgenetics.mergeCorpus(p_cutext=cutext_corpus, p_lookup=lookup_corpus, path_to_words=corpus_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 Representación de clínica sobre una matriz de distribución terminológica\n",
    "Diseñar una función capaz de mapear los términos extraídos al paciente correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la matriz a partir de un dataFrame almacenado como un documento excel\n",
    "nimgenetics.mapeoTerminos(l_textos=path_textos, infile_global=corpus_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 Selección de 500 términos para el mapeo manual a HPO\n",
    "Función que genera dos diccionarios relativo al conteo global de términos y los 500 términos para el mapeo manual a HPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms = nimgenetics.subsetManual(c_uncleaned=lookup_corpus_uncleaned, c_global=corpus_global)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El programa devuelve el conteo global -*all_terms*- gracias a la función items del módulo *FreqDist* de NLTK. \n",
    "\n",
    "Esta lista es utilizada para generar la imagen de la distribución terminológia en función de la frecuencia de los términos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -all_terms- diccionario que integra la lista completa de términos\n",
    "# Los términos aparecen en formato key, value\n",
    "# key = término\n",
    "# value = número de veces que aparece el término\n",
    "\n",
    "# Primera categoría:\n",
    "values_500 = []\n",
    "values_500_50 = []\n",
    "values_50 = []\n",
    "\n",
    "for key, value in all_terms:\n",
    "    \n",
    "    if value > 500:\n",
    "        values_500.append(key)\n",
    "    elif value <= 500 and value >= 50:\n",
    "        values_500_50.append(key)\n",
    "    else:\n",
    "        values_50.append(key)\n",
    "\n",
    "names = ['500', '500-50', '50']\n",
    "values = [len(values_500), len(values_500_50), len(values_50)]\n",
    "\n",
    "# Segunda categoría:\n",
    "# Diccionario con las palabras <= 50 repeticiones en el corpus global\n",
    "dict2 = {k: v for k, v in all_terms if v <= 50}\n",
    "d2 = dict2.items()\n",
    "\n",
    "v_50_25 = []\n",
    "v_25_10 = []\n",
    "v_10 = []\n",
    "\n",
    "for key, value in d2:\n",
    "    \n",
    "    if value <= 50 and value > 25:\n",
    "        v_50_25.append(key)\n",
    "    elif value <= 25 and value > 10:\n",
    "        v25_10.append(key)\n",
    "    else:\n",
    "        v_10.append(key)\n",
    "\n",
    "names1 = ['50-25', '25-10', '10']\n",
    "values1 = [len(v_50_25), len(v_25_10), len(v_10)]\n",
    "\n",
    "# Tercera categoría:\n",
    "# Diccionario con las palabras <= 10 repeticiones en el corpus global\n",
    "dict3 = {k: v for k, v in all_terms if v <= 10}\n",
    "d3 = dict3.items()\n",
    "\n",
    "v_10_5 = []\n",
    "v_5_3 = []\n",
    "v_3 = []\n",
    "\n",
    "for key, value in d3:\n",
    "    \n",
    "    if value <= 10 and value > 5:\n",
    "        v_10_5.append(key)\n",
    "    elif value <= 5 and value > 3:\n",
    "        v_5_3.append(key)\n",
    "    else:\n",
    "        v_3.append(key)\n",
    "        \n",
    "names2 = ['10-5', '5-3', '3']\n",
    "values2 = [len(v_10_5), len(v_5_3), len(v_3)]\n",
    "\n",
    "# Cuarta categoría:\n",
    "# Diccionario con las palabras <= 3 repeticiones en el corpus global\n",
    "dict4 = {k: v for k, v in all_terms if v <= 3}\n",
    "d4 = dict4.items()\n",
    "\n",
    "v_3_ = []\n",
    "v_2_ = []\n",
    "v_1_ = []\n",
    "\n",
    "for key, value in d4:\n",
    "    \n",
    "    if value == 3:\n",
    "        v_3_.append(key)\n",
    "    elif value == 2:\n",
    "        v_2_.append(key)\n",
    "    else:\n",
    "        v_1_.append(key)\n",
    "\n",
    "names3 = ['3', '2', '1']\n",
    "values3 = [len(v_3_), len(v_2_), len(v_1_)]\n",
    "\n",
    "# Plotear la distribución de categorías terminológicas\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "ax0 = fig.add_subplot(111)\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "\n",
    "ax0.spines['top'].set_color('none')\n",
    "ax0.spines['bottom'].set_color('none')\n",
    "ax0.spines['left'].set_color('none')\n",
    "ax0.spines['right'].set_color('none')\n",
    "ax0.tick_params(labelcolor='w', top=False, bottom=False, left=False, right=False)\n",
    "\n",
    "ax0.set_ylabel('Conteo de términos', fontsize=12, labelpad=20)\n",
    "ax0.set_xlabel('Frecuencia de términos', fontsize=12, labelpad=20)\n",
    "\n",
    "ax1.bar(names, values)\n",
    "ax1.set_ylim(0, 4500)\n",
    "\n",
    "ax2.bar(names1, values1)\n",
    "ax2.set_ylim(0, 4500)\n",
    "\n",
    "ax3.bar(names2, values2)\n",
    "ax3.set_ylim(0, 4500)\n",
    "\n",
    "ax4.bar(names3, values3)\n",
    "ax4.set_ylim(0, 4500)\n",
    "\n",
    "fig.suptitle('Categorias Terminológicas', fontsize=20)\n",
    "fig.savefig('distribucion de terminología.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
